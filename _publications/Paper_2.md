---
title: "Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR"
collection: publications
ispaper: "yes"
permalink: /publication/2
excerpt: 'Combining computationally efficient techniques like speech-based parameter-efficient finetuning and text-only adaptation to improve automatic speech recognition of low resource languages using multimodal multilingual models.'
date: 2024-10-10
venue: 'Accepted to the 4th Multilingual Representation Learning Workshop, EMNLP 2024'
slidesurl: 'http://amparulekar.github.io/files/MRL_poster.pdf'
paperurl: 'https://arxiv.org/pdf/2410.13445'
citation: 'Gupta A., Parulekar A., Chattopadhyay S., & Jyothi P. (2024). Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR. https://arxiv.org/abs/2410.13445 '
---

Automatic speech recognition (ASR) for low-resource languages remains challenging due to the limited availability of labeled training data. Parameter-efficient fine-tuning and text-only adaptation are two widely used approaches to address these constraints. In this study, we explore how these techniques can be effectively combined using a multilingual multimodal model like SeamlessM4T. Multimodal models can leverage unlabeled text through text-only adaptation alongside parameter-efficient ASR fine-tuning, resulting in improved ASR performance. Additionally, we demonstrate cross-lingual transfer from a high-resource language, achieving up to a 17% relative reduction in WER in a zero-shot setting without any labeled speech data.
