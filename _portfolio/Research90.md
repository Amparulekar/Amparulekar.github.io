---
title: "Multilingual Automatic Speech Recognition for Low-resource Languages"
excerpt: "*Master’s Thesis-I (Nationwide project - Bhashini, NLTM and the Amazon IITB AI-ML Initiative) at the Computational Speech and Language Technologies Lab, IIT Bombay, Guides: Prof. Preethi Jyothi, Prof. Pushpak Bhattacharya*"
isresearch: "yes"
isacademic: "no"
isintern: "no"
isnlp: "yes"
iscv: "no"
collection: portfolio
---

*Master’s Thesis-I (Nationwide project - Bhashini, NLTM and the Amazon IITB AI-ML Initiative) at the Computational Speech and Language Technologies Lab, IIT Bombay, Guides: Prof. Preethi Jyothi, Prof. Pushpak Bhattacharya*

**Summary:** *This project involves creating multilingual Automatic Speech Recognition tools robust to mispronunciation, along with requiring low computation, less data and specifically catering to low resource languages.*

*Paper published at the  2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL 2025)*

[**Paper 2 link**](https://arxiv.org/pdf/2411.18368), [**Poster link**](http://amparulekar.github.io/files/NAACL_2025_564_AMPS.pdf)

*Paper published at the 4th Multilingual Representation Learning workshop, EMNLP 2024*

[**Paper 1 link**](https://arxiv.org/pdf/2410.13445), [**Poster link**](http://amparulekar.github.io/files/MRL_poster.pdf)

* Designed a novel strategy to incorporate paraphrase supervision in multimodal models and improve ASR for noisy speech
* Developed a novel sequential method to combine speech-based parameter-efficient fine-tuning and text-only adaptation for multimodal multilingual models like SeamlessM4T, improving ASR on 10+ low-resource Indian and African languages
* Obtained a 40% WER reduction over baseline on IndicVoices-Maithili and identified a cross-lingual transfer technique that can give more than 17% relative reduction in WER for a low-resource language without using any speech of that language
