---
title: "Hallucination Detection and Mitigation in Large Language Models"
excerpt: "*Research Assistant at the Crowd Dyanamics Lab, UIUC, Guide: Prof. Hari Sundaram*"
isresearch: "yes"
isacademic: "no"
isintern: "no"
isnlp: "yes"
iscv: "no"
collection: portfolio
---

*Research Assistant at the Crowd Dyanamics Lab, UIUC, Guide: Prof. Hari Sundaram*

**Summary:** *This project aims to use causal inference and activation analysis to understand and mitigate LLM hallucinations.*

* Utilizing causal inference and ensembling strategies to improve LLM reasoning on Legal and Medical domain data.
* Using LLM circuit analysis to analyze the impact of toxicity on LLMs and to mitigate its propagation to hallucinations.
